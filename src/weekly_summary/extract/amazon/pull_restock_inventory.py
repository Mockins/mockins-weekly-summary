from __future__ import annotations

import os
import time
from dataclasses import dataclass
from datetime import date, datetime, timedelta, timezone
from pathlib import Path
from typing import Optional

from sp_api.api import Reports
from sp_api.base import Marketplaces
from sp_api.base.exceptions import SellingApiRequestThrottledException

from .report_utils import download_report_document, wait_for_report

REPORT_TYPE = "GET_RESTOCK_INVENTORY_RECOMMENDATIONS_REPORT"


@dataclass(frozen=True)
class RestockPullResult:
    report_type: str
    report_id: str
    document_id: str
    raw_path: Path


def _today_str() -> str:
    return date.today().isoformat()


def _default_cache_dir() -> Path:
    return Path("data") / "raw" / "amazon" / "restock_inventory" / _today_str()


def _build_reports_client() -> Reports:
    refresh_token = os.getenv("SPAPI_REFRESH_TOKEN")
    lwa_app_id = os.getenv("SPAPI_LWA_APP_ID")
    lwa_client_secret = os.getenv("SPAPI_LWA_CLIENT_SECRET")

    if not refresh_token or not lwa_app_id or not lwa_client_secret:
        raise RuntimeError(
            "Missing SP-API env vars. Need SPAPI_REFRESH_TOKEN, SPAPI_LWA_APP_ID, SPAPI_LWA_CLIENT_SECRET"
        )

    return Reports(
        credentials={
            "refresh_token": refresh_token,
            "lwa_app_id": lwa_app_id,
            "lwa_client_secret": lwa_client_secret,
        },
        marketplace=Marketplaces.US,
    )


def _iso_utc(dt: datetime) -> str:
    return dt.astimezone(timezone.utc).replace(microsecond=0).isoformat().replace("+00:00", "Z")


def _get_latest_done_report(reports: Reports, lookback_days: int = 7) -> Optional[tuple[str, str]]:
    """
    Returns (report_id, report_document_id) for the most recent DONE report, or None.
    """
    created_since = _iso_utc(datetime.now(timezone.utc) - timedelta(days=lookback_days))

    # get_reports can also throttle, so keep it conservative with retries
    for attempt in range(1, 6):
        try:
            res = reports.get_reports(
                reportTypes=[REPORT_TYPE],
                processingStatuses=["DONE"],
                createdSince=created_since,
                pageSize=10,
            )
            payload = res.payload or {}
            items = payload.get("reports") or []
            if not items:
                return None

            # Sort by createdTime ascending, take newest
            def _created_time(r: dict) -> str:
                return r.get("createdTime") or ""

            items_sorted = sorted(items, key=_created_time)
            newest = items_sorted[-1]

            report_id = newest.get("reportId")
            doc_id = newest.get("reportDocumentId")
            if report_id and doc_id:
                return report_id, doc_id

            return None

        except SellingApiRequestThrottledException:
            wait_s = 5 * attempt
            print(f"Throttled on get_reports. Waiting {wait_s}s (attempt {attempt}/5)...")
            time.sleep(wait_s)

    return None


def _create_report_with_backoff(
    reports: Reports,
    report_type: str,
    max_attempts: int = 8,
) -> str:
    for attempt in range(1, max_attempts + 1):
        try:
            res = reports.create_report(reportType=report_type)
            return res.payload["reportId"]
        except SellingApiRequestThrottledException:
            wait_s = 30 * attempt
            print(f"Throttled on create_report. Waiting {wait_s}s (attempt {attempt}/{max_attempts})...")
            time.sleep(wait_s)

    raise RuntimeError("Exceeded max attempts creating restock report due to throttling.")


def pull_restock_inventory_raw(
    *,
    cache_dir: Optional[Path] = None,
    reuse_if_exists: bool = True,
    lookback_days: int = 7,
) -> RestockPullResult:
    """
    Pull Restock Inventory report and cache raw file.

    Order of operations:
    1) If reuse_if_exists and cached file exists in today's cache_dir, use it.
    2) Else, try to find the newest DONE report already generated by Amazon (get_reports),
       download it, cache it locally, then use it.
    3) Else, create_report + wait + download, then cache it.
    """
    cache_dir = cache_dir or _default_cache_dir()
    cache_dir.mkdir(parents=True, exist_ok=True)

    existing = sorted(cache_dir.glob("restock_inventory_raw_*"))
    if reuse_if_exists and existing:
        raw_path = existing[-1]
        print(f"Using cached restock report: {raw_path}")
        return RestockPullResult(
            report_type=REPORT_TYPE,
            report_id="cached",
            document_id="cached",
            raw_path=raw_path,
        )

    reports = _build_reports_client()

    latest = _get_latest_done_report(reports, lookback_days=lookback_days)
    if latest is not None:
        report_id, document_id = latest
        print(f"Reusing newest DONE restock report from Amazon: reportId={report_id}")

        doc = reports.get_report_document(reportDocumentId=document_id).payload
        content = download_report_document(doc)

        raw_path = cache_dir / f"restock_inventory_raw_{report_id}.txt"
        raw_path.write_bytes(content)
        print(f"Saved raw restock report: {raw_path}")

        return RestockPullResult(
            report_type=REPORT_TYPE,
            report_id=report_id,
            document_id=document_id,
            raw_path=raw_path,
        )

    print("No recent DONE report found. Creating Restock Inventory report...")
    report_id = _create_report_with_backoff(reports, REPORT_TYPE)
    print(f"Created reportId={report_id}")

    print("Waiting for report to finish...")
    document_id = wait_for_report(reports, report_id)
    print(f"DONE documentId={document_id}")

    doc = reports.get_report_document(reportDocumentId=document_id).payload
    content = download_report_document(doc)

    raw_path = cache_dir / f"restock_inventory_raw_{report_id}.txt"
    raw_path.write_bytes(content)
    print(f"Saved raw restock report: {raw_path}")

    return RestockPullResult(
        report_type=REPORT_TYPE,
        report_id=report_id,
        document_id=document_id,
        raw_path=raw_path,
    )
